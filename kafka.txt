i) CD into Kafka folder

cd kafka_2.10-0.8.2.2/

ii) Start the zookeeper

bin/zookeeper-server-start.sh config/zookeeper.properties

(typically the zookeeper is running on port no:2181)

iii)Start the kafka server (run below command in a new tab)

bin/kafka-server-start.sh config/server.properties

(The kafka port which will be running is : 9092)

iv)Create topic (run below command in a new tab)

bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic testtopic_new

v)List topic

bin/kafka-topics.sh --list --zookeeper localhost:2181

vi)Publish to kafka with producer (run below command in a new tab)

bin/kafka-console-producer.sh --broker-list localhost:9092 --topic testtopic_new

Now type some message here in the terminal.

vii)Consumer from kafka (run below command in a new tab)

bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic testtopic_new --from-beginning

The message you write in producer will be reflected here on real time basis.

Kafka classes::
---------------
kafka.javaapi.producer.Producer Class provides the Producer messages.

//The producer class is a java generic type Producer<K,V>

//K is a key type to throw the message to which partition.
//V is the type of the message type.

Producer(producerConfig)
//The producerConfig is required to connect with the brokers mentioned in the configuration.
//The producerConfig class is present in the kafka.producer.ProducerConfig
close()
send(KeyedMessage<k,v>
//keyedMessage is present in the kafka.producer.KeyedMessage

class KeyedMessage[K, V](val topic: String, val key: K, val message: V)

send(List<KeyedMessage<k,v>>)


The Kafka producer property list::
----------------------------------
The following table shows a list of a few important properties that can be configured for
Kafka producer. The Scala class kafka.producer.ProducerConfig provides
implementation-level details for producer configurations. For the complete list, visit
http://kafka.apache.org/documentation.html#producerconfigs.
Property name Description Default value

metadata.broker.list::

The producer uses this property to get metadata
(topics, partitions, and replicas). The socket
connections for sending the actual data will be
established based on the broker information
returned in the metadata. The format is
host1:port1,host2:port2 .

serializer.class::

This specifies the serializer class for the
messages. The default encoder accepts a byte and
returns the same byte.

kafka.serializer.DefaultEncoder

producer.type::

This property specifies how the messages will be
sent:
async for asynchronous sending (used with
message batching)
sync for synchronous sending

sync

request.required.acks::

This value controls when the producer request is
considered complete and whether the producer
receives an acknowledgment from the broker:
0 means the producer will never wait for an
acknowledgment from the broker. This is
used for the lowest latency, but with the
weakest durability.
1 means the producer receives an
acknowledgment once the lead replica has
received the data. This option provides better
durability as the client waits until the server
acknowledges the request as successful.
-1 means the producer will receive an
acknowledgment once all the in-sync replicas
have received the data. This option provides
the best durability.

0

key.serializer.class::

This specifies the serializer class for keys.
${serializer.class}

partitioner.class

This is the partitioner class for partitioning
messages among subtopics. The default partitioner
is based on the hash value of the key.
kafka.producer.DefaultPartitioner

compression.codec::

This parameter specifies the compression codec for
all data generated by this producer. Valid values are
none , gzip , and snappy .
none
This specifies the number of messages to be sent in

batch.num.messages::

one batch when using async mode. The producer
will wait until this quantity of messages is ready to
be sent or queue.buffer.max.ms is reached.

200

Consumers::
-----------





kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 3 --topic kafkatopic


java -cp examples.jar kafka.examples.ch4.SimpleProducer.class kafkatopic 10

/home/edureka/kafka_2.10-0.8.2.2/libs

export KAFKA_LIB=/home/edureka/kafka_2.10-0.8.2.2/libs

export CLASSPATH=.:$KAFKA_LIB/jopt-simple-3.2.jar:$KAFKA_LIB/kafka_2.10-0.8.2.2.jar:$KAFKA_LIB/log4j-1.2.16.jar:$KAFKA_LIB/metrics-core-2.2.0.jar:$KAFKA_LIB/scala-library-2.10.4.jar:$KAFKA_LIB/slf4j-api-1.7.6.jar:$KAFKA_LIB/slf4j-log4j12-1.6.1.jar:$KAFKA_LIB/snappy-java-1.0.5.jar:$KAFKA_LIB/zkclient-0.3.jar:$KAFKA_LIB/zookeeper-3.4.6.jar:$KAFKA_LIB/kafka-clients-0.8.2.2.jar


java
kafka.examples.ch4.SimpleProducer kafkatopic 100

java kafka.examples.ch4.SimpleProducer kafkatopic1 10000

java kafka.examples.ch5.SimpleHLConsumer localhost:2181 testgroup kafkatopic

java kafka.examples.ch5.MultiThreadHLConsumer localhost:2181 testgroup kafkatopic 4

kafka_2.10-0.8.2.2.jar

kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 5 --topic website-hits



java kafka.examples.ch4.CustomPartitionProducer website-hits 100














bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic kafkatopic --partitions 4 --replication-factor 2


























Doubts::
If the kafka brokers is running in 100 machines does all the brokers need to be passed in the properties.
